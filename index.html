<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    heading2 {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/science.png">
  <title>Jonathan Richard Schwarz</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="90%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Jonathan Richard Schwarz</name>
              </p>              <p>
              I'm a Senior Research Scientist at <a href="https://deepmind.com">DeepMind</a> working on all forms of Efficient Machine Learning. Previously, I was part of the joint DeepMind-<a href="https://www.ucl.ac.uk/">University College London</a> PhD programme, advised by <a href="https://www.stats.ox.ac.uk/~teh/">Yee Whye Teh</a> and <a href="http://www.gatsby.ucl.ac.uk/~pel/">Peter Latham</a>. My
              thesis was focused on the use of sparse parameterisations and knowledge transfer towards this purpose. Befort that, I spent two years at the <a href="https://www.ucl.ac.uk/gatsby/gatsby-computational-neuroscience-unit/">Gatsby Computational Neuroscience Unit</a> and graduated top-of-the class from <a href="https://www.ed.ac.uk/informatics">The University of Edinburgh</a>.
              </p>
              <p>
              My research focuses on the objective of building (i) <b>efficient</b>, (ii) <b>general</b> and (iii) <b>robust</b> Machine Learning systems. A central paradigm in my approach is the design of algorithms that can effectively abstract knowledge and skills present in related problems, enabling their utilisation for efficient learning on future tasks. In this way, agents gradually build diverse repertoires of skills allowing transfer to future tasks using only a fraction of the otherwise required learning time and/or data. To that end, most of my existing work falls within one or more of the following categories:

                <ul>
                  <li>Meta-Learning:
                        <a href="https://arxiv.org/abs/1807.01622">[ICML WS'18]</a>
                        <a href="http://bayesiandeeplearning.org/2018/papers/92.pdf">[NeurIPS WS'18]</a>
                        <a href="https://arxiv.org/abs/1901.05761">[ICLR'19]</a>
                        <a href="http://arxiv.org/abs/1903.11907">[arxiv'19]</a>
                        <a href="https://arxiv.org/abs/2205.08957">[TMLR'22]</a>
                        <a href="https://arxiv.org/abs/2301.09479">[ICML'23]</a>
                        <a href="https://arxiv.org/abs/2302.00617">[arxiv'23]</a>
                  </li>
                  <li>Continual Learning:
                        <a href="https://arxiv.org/abs/1805.06370">[ICML'18]</a>
                        <a href="https://arxiv.org/abs/1811.11682">[NeurIPS'19]</a>
                        <a href="https://arxiv.org/abs/1901.11356">[ICLR'20]</a>
                        <a href="https://arxiv.org/abs/2110.00296">[NeurIPS'21]</a>
                  </li>
                  <li>Sparsity & Efficient Parameterizations:
                        <a href="https://arxiv.org/abs/1905.01240">[ICLR'19]</a>
                        <a href="https://openreview.net/forum?id=rylnK6VtDH">[ICLR'20]</a>
                        <a href="https://arxiv.org/abs/2110.00296">[NeurIPS'21]</a>
                        <a href="https://arxiv.org/abs/2205.08957">[TMLR'22]</a>
                        <a href="https://arxiv.org/abs/2010.14274">[JMLR'22]</a>
                        <a href="https://arxiv.org/abs/2301.09479">[ICML'23]</a></li>
                  <li>Representation learning / INRs:
                        <a href="https://arxiv.org/abs/2205.08957">[TMLR'22]</a>
                        <a href="https://arxiv.org/abs/2301.09479">[ICML'23]</a></li>
                        <a href="https://arxiv.org/abs/2302.03130">[ICLR WS'23]</a>
                        <a href="https://arxiv.org/abs/2302.00617">[arxiv'23]</a>
                </ul>
              </p>

My work has tackled numerous problems with common applications in <b>(a)</b> Large scale (self-) supervised learning (Computer vision, Language) <b>(b)</b> Probabilistic/Generative modeling <b>(c)</b> Sequential Decision Making (RL, Bandits) <b>(d)</b> Implicit Neural Representations (INRs) & Neural data compression.

              <p>
I'm also passionate about equal opportunity & STEM education and frequently participate in outreach events. If you're interested in organising such an event please feel free to contact me.
              </p>
              <p align=center>
                <a href="mailto:schwarzjn@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.uk/citations?user=Efs3XxQAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/schwarzjn_">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/schwarzjonathan/">LinkedIn</a> &nbsp/&nbsp
                Full CV: <i>on request</i>
              </p>
            </td>
            <td width="33%">
              <img width="120%" src="images/jonathan_schwarz_circle.jpg">
            </td>
          </tr>
        </table>
        
	<heading>News</heading>
	<br>
	<br>
	<ul>
	  <li>Invited talk at Havard University on "Towards efficient and robust Machine Learning  @ Harvard [Talk]" (June 2023).</a></li>
	  <li>I'm visiting ETH Zurich to give a talk on Neural data compression with INRs (May 2023).</a></li>
	  <li>Join me and my co-organisers at the <a href="https://sites.google.com/view/neural-fields/">ICLR 2023 workshop on Neural Fields</a></li>
	  <li><a href="https://arxiv.org/abs/2301.09479">VC-INR</a> accepted to ICML 2023!</li>
	  <li>Released our new paper on <a href="https://arxiv.org/abs/2301.09479">Modality-agnostic data compression!</a> (Feb 2023).</li>
	  <li>We have a new paper on <a href="https://arxiv.org/abs/2302.00617">Efficient Meta-Learning for large context sets.</a> (Feb 2023).</li>
	  <li>New work on <a href="https://arxiv.org/abs/2302.03130">Spatial Functa</a>! (Feb 2023).</li>
	  <li>Had a great time visiting <a href="https://www.hku.hk/">The University of Hong Kong</a> and <a href="https://www.hku.hk/">City University of Hong Kong</a> (November 2022).</li>
	  <li>I'm giving a talk at <a href="https://www.cam.ac.uk/">The University of Cambridge</a> on sparsity techniques for Meta & Continual Learning (October 2022).</li>
	  <li><a href="https://arxiv.org/abs/2010.14274"> Behavior priors for efficient reinforcement learning</a> was accepted to JMLR (September 2022)!</li>
	  <li><a href="https://arxiv.org/abs/2205.08957"> Meta-Learning Sparse Compression Networks (MSCN)</a> was accepted to TMLR (August 2022)!</li>
	  <li>I'm giving a talk at <a href="https://www.tue.nl/en/">TU Eindhoven</a> on sparsity techniques for Continual Learning (June 2022).</li>
	  <li>Honoured to be invited to the <a href="https://sites.google.com/view/clvision2022/overview">CVPR 2022 Workshop on CL for Vision</a> to speak about sparsity techniques for Continual Learning and participate at the panel discussion. (June 2022)</li>
	  <li>I'm giving a talk at <a href="https://www.kaist.ac.kr/en/">KAIST</a> on our new paper "Meta-learning Sparse Compression Networks" (May 2022)</li>
	  <li>My new paper on Meta-learned Sparsity and compression with INRs is <a href="https://arxiv.org/abs/2205.08957?context=cs.LG">now available!</a></li>
	  <li><a href="https://arxiv.org/abs/2110.00296"> Powerpropagation</a> accepted to NeurIPS 2021 and as a spotlight talk at <a href="https://sites.google.com/view/sparsity-workshop-2021/home">Sparsity in Neural Networks 2021</a>!</li>
	  <li>The <a href="https://meta-learn.github.io/2021/"> Workshop on Meta Learning</a> is back at NeurIPS 2021</li>
	  <li>I'm giving a lecture on Deep Learning with Low Resources @ IndabaX Sudan (September 2021)</li>
	  <li>I'm giving a lecture on Meta & Continual Learning at the Polytechnic University of Bucharest (July 2021)</li>
	  <li><a href="https://arxiv.org/abs/2110.00296"> Powerpropagation</a> was accepted as a Spotlight talk at the Sparsity in Neural Networks 2021 Workshop!</li>
	  <li>We are organising a (virtual) <a href="https://meta-learn.github.io/2020/"> Workshop on Meta Learning</a> at NeurIPS 2020</li>
	  <li>Talk on Continual Learning @ Kheiron Medical (June 2020)</li>
	  <li>We are organising a (virtual) <a href="https://sites.google.com/view/cl-icml"> Workshop on Continual Learning</a> at ICML 2020</li>
	  <li><a href="https://arxiv.org/abs/1901.11356">Functional regularisation for continual learning</a> got accepted to ICLR 2020!</li>
	  <li><a href="https://openreview.net/forum?id=rylnK6VtDH">Multiplicative Interactions and Where to Find Them</a> got accepted to ICLR 2020!</li>
	</ul>
	<br>
	<br>
	
        <heading>Research</heading>
	<br>
	<br>
	<center>
	Selected papers are <span class="highlight">highlighted</span>.

	<br>
	<heading2>All papers</heading2>
	<br>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <td width="25%"><img src="images/vc_inr.png" alt="clean-usnob" width="160" height="160"></td>
          <td width="75%" valign="top">
            <p>
              <p>
                <a href="https://arxiv.org/abs/2301.09479">
                  <papertitle>Modality-Agnostic Variational Compression of Implicit Neural Representations (VC-INR)</papertitle>
                </a>
                <br>
                <strong>Jonathan Richard Schwarz</strong>*, Jihoon Tack*, Yee Whye Teh, Jaeho Lee, Jinwoo Shin
		<br>
	  	<br>
		<em>ICML 2023</em>
		<br>
		<br>
	  	<em>* : Joint first authorship</em>
              </p>
          </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <td width="25%"><img src="images/ecop.png" alt="clean-usnob" width="160" height="140"></td>
          <td width="75%" valign="top">
            <p>
              <p>
                <a href="https://arxiv.org/abs/2302.00617">
                  <papertitle>Efficient Meta-Learning via Error-based Context Pruning for Implicit Neural Representations</papertitle>
                </a>
                <br>
                Jihoon Tack, Subin Kim, Sihyun Yu, Jaeho Lee, Jinwoo Shin, <strong>Jonathan Richard Schwarz</strong>
		<br>
	  	<br>
		<em>arXiv 2023</em>
              </p>
          </td>
        </table>
		
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <td width="25%"><img src="images/spatial_functa.png" alt="clean-usnob" width="160" height="140"></td>
          <td width="75%" valign="top">
            <p>
              <p>
                <a href="https://arxiv.org/abs/2302.03130">
                  <papertitle>Spatial Functa: Scaling Functa to ImageNet Classification and Generation</papertitle>
                </a>
                <br>
		Matthias Bauer*, Emilien Dupont, Andy Brock, Dan Rosenbaum, <strong>Jonathan Richard Schwarz</strong>, Hyunjik Kim*
		<br>
	  	<br>
		<em>arXiv 2023</em>
		<br>
		<br>
              </p>
          </td>
        </table>	
		
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <td width="25%"><img src="images/mscn.png" alt="clean-usnob" width="160" height="140"></td>
          <td width="75%" valign="top">
            <p>
              <p>
                <a href="https://arxiv.org/abs/2205.08957">
                  <papertitle>Meta-Learning Sparse Compression Networks (MSCN)</papertitle>
                </a>
                <br>
                <strong>Jonathan Richard Schwarz</strong>, Yee Whye Teh
                <br>
                <br>
                <em>Transactions on Machine Learning Research (TMLR) 2022</em>
                <br>
                <br>
              </p>
          </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <td width="25%"><img src="images/bpriors.png" alt="clean-usnob" width="160" height="120"></td>
          <td width="75%" valign="top">
            <p>
              <p>
                <a href="https://arxiv.org/abs/2010.14274">
                  <papertitle>Behavior Priors for Efficient Reinforcement Learning</papertitle>
                </a>
                <br>
		Dhruva Tirumala, Alexandre Galashov, Hyeonwoo Noh, Leonard Hasenclever, Razvan Pascanu, <strong>Jonathan Richard Schwarz</strong>, Guillaume Desjardins, Wojciech Marian Czarnecki, Arun Ahuja, Yee Whye Teh, Nicolas Heess
                <br>
                <br>
                <em>Journal of Machine Learning Research (JMLR) 2022</em>
                <br>
                <br>
              </p>
          </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <td width="25%"><img src="images/powerprop.png" alt="clean-usnob" width="160" height="140"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="https://arxiv.org/abs/2110.00296">
                    <papertitle>Powerpropagation: A sparsity inducing weight reparameterisation</papertitle>
                  </a>
                  <br>
                  <strong>Jonathan Richard Schwarz</strong>, Siddhant M. Jayakumar, Razvan Pascanu, Peter E. Latham, Yee Whye Teh
                  <br>
                  <br>
                  <em>Neural Information Processing Systems (NeurIPS) 2021</em>
                  <br>
                  <br>
                  <a href="https://github.com/deepmind/deepmind-research/tree/master/powerpropagation">Code</a>
                </p>
            </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr bgcolor="#ffffd0">
            <td width="25%"><img src="images/gp.png" alt="clean-usnob" width="160" height="140"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="https://arxiv.org/abs/1901.11356">
                    <papertitle>Functional Regularisation for Continual Learning using Gaussian Processes</papertitle>
                  </a>
                  <br>
                  <strong>Jonathan Richard Schwarz</strong>*, Michalis K. Titsias*, Alexander G. de G. Matthews, Razvan Pascanu, Yee Whye Teh
                  <br>
                  <br>
                  <em>International Conference on Learning Representations (ICLR) 2020</em>
                  <br>
                  <br>
                  <a href="https://github.com/deepmind/deepmind-research/blob/master/functional_regularisation_for_continual_learning/frcl.ipynb">Code</a>
		  <br>
                  <br>
                  <em>* : Joint first authorship</em>
                </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <td width="25%"><img src="images/multi.png" alt="clean-usnob" width="160" height="120"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="https://openreview.net/forum?id=rylnK6VtDH">
                    <papertitle>Multiplicative Interactions and Where to Find Them</papertitle>
                  </a>
                  <br>
                  Siddhant M. Jayakumar, Wojciech M. Czarnecki, Jacob Menick, <strong>Jonathan Richard Schwarz</strong>, Jack Rae, Simon Osindero, Yee Whye Teh, Tim Harley, Razvan Pascanu
                  <br>
                  <br>
                  <em>International Conference on Learning Representations (ICLR) 2020</em>
                  <br>
                  <br>
                </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <td width="25%"><img src="images/np_model_based.png" alt="clean-usnob" width="160" height="140"></td>
          <td width="75%" valign="top">
            <p>
              <p>
                <a href="http://arxiv.org/abs/1903.11907">
                  <papertitle>Meta-Learning surrogate models for sequential decision making</papertitle>
                </a>
                <br>
                  <strong>Jonathan Richard Schwarz</strong>*, Alexandre Galashov*, Hyunjik Kim, Marta Garnelo, David Saxton, Pushmeet Kohli, SM Ali Eslami°, Yee Whye Teh°
                <br>
                <br>
                <em>ICLR 2019 Workshop on Structure & Priors in Reinforcement Learning</em>
                <br>
                <br>
                <em>*, ° : Joint first/senior authorship</em>
              </p>
          </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="images/storage.png" alt="clean-usnob" width="140" height="120",  class="center"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="https://arxiv.org/abs/1811.11682">
                    <papertitle>Experience replay for continual learning</papertitle>
                  </a>
                  <br>
                  David Rolnick, Arun Ahuja, <strong>Jonathan Richard Schwarz</strong>, Timothy P. Lillicrap, Greg Wayne
                  <br>
                  <br>
                  <em>Neural Information Processing Systems (NeurIPS) 2019</em>
                </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img src="images/kl.png" alt="clean-usnob" width="160" height="130"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="https://arxiv.org/abs/1905.01240">
                    <papertitle>Information asymmetry in KL-regularized RL</papertitle>
                  </a>
                  <br>
                  Alexandre Galashov, Siddhant M Jayakumar, Leonard Hasenclever, Dhruva Tirumala, <strong>Jonathan Richard Schwarz</strong>, Guillaume Desjardins, Wojciech M Czarnecki, Yee Whye Teh, Razvan Pascanu, Nicolas Heess
                  <br>
                  <br>
                  <em>International Conference on Learning Representations (ICLR) 2019</em>
                </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img src="images/comparison.png" alt="clean-usnob" width="160" height="130"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="http://bayesiandeeplearning.org/2018/papers/92.pdf">
                    <papertitle>Empirical Evaluation of Neural Process Objectives</papertitle>
                  </a>
                  <br>
                  Tuan Anh Le, Hyunjik Kim, Marta Garnelo, Dan Rosenbaum, <strong>Jonathan Richard Schwarz</strong>, Yee Whye Teh
                  <br>
                  <br>
                  <em>NeurIPS 2018 workshop on Bayesian Deep Learning</em>
                </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img src="images/anp.png" alt="clean-usnob" width="160" height="160"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="https://arxiv.org/abs/1901.05761">
                    <papertitle>Attentive Neural Processes</papertitle>
                  </a>
                  <br>
                  Hyunjik Kim, Andriy Mnih, <strong>Jonathan Richard Schwarz</strong>, Marta Garnelo, SM Ali Eslami, Dan Rosenbaum, Oriol Vinyals, Yee Whye Teh
                  <br>
                  <br>
                  <em>International Conference on Learning Representations (ICLR) 2019</em>
                  <br>
                  <br>
                  <a href="https://github.com/deepmind/neural-processes">Code</a>
                </p>
            </td>
          </tr>
          <tr bgcolor="#ffffd0">
            <td width="25%"><img src="images/np.png" alt="clean-usnob" width="160" height="140"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="https://arxiv.org/abs/1807.01622">
                    <papertitle>Neural Processes</papertitle>
                  </a>
                  <br>
                  Marta Garnelo, <strong>Jonathan Richard Schwarz</strong>, Dan Rosenbaum, Fabio Viola, Danilo J Rezende, SM Eslami, Yee Whye Teh
                  <br>
                  <br>
                  <em>ICML 2018 Workshop on Theoretical Foundations and Applications of Deep Generative Models</em> <font color="red"><strong> (Spotlight talk)</strong></font>
                  <br>
                  <br>
                  <a href="https://github.com/deepmind/neural-processes">Code</a> / <a href="https://www.youtube.com/watch?v=bpsoGt-NYYk">Talk</a> (credit to Marta)
                </p>
            </td>
          </tr>
          <tr bgcolor="#ffffd0">
            <td width="25%"><img src="images/p_and_c.png" alt="clean-usnob" width="160" height="120"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="https://arxiv.org/abs/1805.06370">
                    <papertitle>Progress & Compress: A scalable framework for continual learning</papertitle>
                  </a>
                  <br>
                  <strong>Jonathan Richard Schwarz</strong>, Jelena Luketina, Wojciech M. Czarnecki, Agnieszka Grabska-Barwinska, Yee Whye Teh, Raia Hadsell°, Razvan Pascanu°
                  <br>
                  <br>
                  <em>International Conference on Machine Learning (ICML) 2018</em> <font color="red"><strong> (Long oral Presentation)</strong></font>
                  <br>
                  <br>
                  <a href="https://drive.google.com/drive/folders/1CWDGnf_a5YIJH1a9sUNdQsYtRxal4nxf?usp=sharing">Sequential Omniglot Dataset</a> / <a href="https://www.facebook.com/icml.imls/videos/session-3-deep-learning-neural-network-architectures/432573817257139">Talk</a>
                  <br>
                  <br>
                  <em>° : Joint senior authorship</em>
                </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img src="images/narrative_qa.png" alt="clean-usnob" width="160" height="160"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="https://arxiv.org/abs/1712.07040">
                    <papertitle>The NarrativeQA Reading Comprehension Challenge</papertitle>
                  </a>
                  <br>
                  Tomas Kocisky, <strong>Jonathan Richard Schwarz</strong>, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gabor Melis, Edward Grefenstette
                  <br>
                  <br>
                  <em>Transactions of the Association for Computational Linguistics (TACL) 2018</em>
                  <br>
                  <br>
                  <a href="https://github.com/deepmind/narrativeqa">Dataset</a> / <a href="https://vimeo.com/285804931">Talk</a> (credit to Tomas)
                </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img src="images/recurrent_vae.png" alt="clean-usnob" width="160" height="140"></td>
            <td width="75%" valign="top">
              <p>
                <p>
                  <a href="http://www.ipab.inf.ed.ac.uk/cgvu/0414.pdf">
                    <papertitle>A Recurrent Variational Autoencoder for Human Motion Synthesis</papertitle>
                  </a>
                  <br>
                  Ikhsanul Habibie, Daniel Holden, <strong>Jonathan Richard Schwarz</strong>, Joe Yearsley, Taku Komura
                  <br>
                  <br>
                  <em>British Machine Vision Conference (BMVC) 2017</em>
                  <br>
                  <br>
		  <a href="https://github.com/Brimborough/deep-motion-analysis">Code</a> / <a href="https://bitbucket.org/jonathan-schwarz/edinburgh_locomotion_mocap_dataset">Dataset</a>
                </p>
            </td>
          </tr>
        </table>

	<br>
	<heading2>Service</heading2>
	<br>
	<br>
	<br>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <td width="15%"><img src="images/neural_fields.png" alt="clean-usnob" width="120" height="100"></td>
            <td width="85%" valign="top">
              <p>
                <p>
                  <a href="https://sites.google.com/view/neural-fields">
                    <papertitle>(ICLR 2023) Neural Fields across Fields: Methods and Applications of Implicit Neural Representations</papertitle>
                  </a>
                  <br>
                  <strong>Jonathan Richard Schwarz</strong>, Hyunjik Kim, Emilien Dupont, Thu Nguyen-Phuoc, Vincent Sitzman, Srinath Sridhar
                  <br>
                  <br>
                </p>
            </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <td width="15%"><img src="images/neurips.jpeg" alt="clean-usnob" width="120" height="100"></td>
            <td width="85%" valign="top">
              <p>
                <p>
                  <a href="https://meta-learn.github.io/2021/">
                    <papertitle>NeurIPS 2021 Workshop on Meta Learning</papertitle>
                  </a>
                  <br>
                  <strong>Jonathan Richard Schwarz</strong>, Fábio Ferreira, Erin Grant, Frank Hutter, Joaquin Vanschoren, Huaxiu Yao
                  <br>
                  <br>
                </p>
            </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <td width="15%"><img src="images/neurips.jpeg" alt="clean-usnob" width="120" height="100"></td>
            <td width="85%" valign="top">
              <p>
                <p>
                  <a href="https://meta-learn.github.io/2020/">
                    <papertitle>NeurIPS 2020 Workshop on Meta Learning</papertitle>
                  </a>
                  <br>
                  <strong>Jonathan Richard Schwarz</strong>, Roberto Calandra , Jeff Clune , Erin Grant, Joaquin Vanschoren, Francesco Visin, Jane Wang
                  <br>
                  <br>
                </p>
            </td>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <td width="15%"><img src="images/icml_cl.png" alt="clean-usnob" width="120" height="100"></td>
            <td width="85%" valign="top">
              <p>
                <p>
                  <a href="https://sites.google.com/view/cl-icml/">
                    <papertitle>ICML 2020 Workshop on Continual Learning</papertitle>
                  </a>
                  <br>
                  <strong>Jonathan Richard Schwarz</strong>, Rahaf Aljundi, Eugene Belilovsky, Arslan Chaudhry, Puneet Dokania, Sayna Ebrahimi, Haytham Fayek, David Lopez-Paz , Marc Pickett
                  <br>
                  <br>
                </p>
            </td>
        </table>

  Based on <a href="https://jonbarron.info/">Jon Barron's</a> website.

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-62553068-1', 'auto');
ga('send', 'pageview');
</script>
<!-- End Google Analytics -->

</body>

</html>
